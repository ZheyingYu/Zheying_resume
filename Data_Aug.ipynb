{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AFgf_b3Qfpo"
   },
   "outputs": [],
   "source": [
    " from numpy import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from google.colab import drive\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "-Vzu7t1WQrM6",
    "outputId": "defe283b-b66e-435a-eee8-65b6778ff5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.config', 'gdrive', 'sample_data']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive.mount('/content/gdrive',force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/\"\n",
    "base_dir = root_dir + 'Segmented Numpy Data/'\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ui3nRjOQQ218"
   },
   "outputs": [],
   "source": [
    "#prepare the data from the images we cut\n",
    "\n",
    "data_output = np.zeros((1,6443008))\n",
    "data_input = np.zeros((1,6443008)) \n",
    "all_files = sorted(os.listdir(base_dir))\n",
    "\n",
    "for i in range(0,174):\n",
    "    filename = all_files[i]\n",
    "    if filename.endswith(\"seg.npz\"): \n",
    "      dict_data1 = load(base_dir + filename)\n",
    "      data_temp1 = dict_data1['arr_0']\n",
    "      data_temp1 = data_temp1.reshape(1,6443008)\n",
    "      data_output = np.vstack((data_output,data_temp1))\n",
    "    else:\n",
    "      dict_data2 = load(base_dir + filename)\n",
    "      data_temp2 = dict_data2['arr_0']\n",
    "      data_temp2 = data_temp2.reshape(1,6443008)\n",
    "      data_input = np.vstack((data_input,data_temp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "sOHKNhGeVVt0",
    "outputId": "285613f2-eb43-49cd-d0a8-fcd86357a17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 6443008)\n",
      "(87, 6443008)\n"
     ]
    }
   ],
   "source": [
    "data_output = np.delete(data_output,0, axis = 0)\n",
    "data_input = np.delete(data_input,0,axis = 0)\n",
    "print(data_output.shape)\n",
    "print(data_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5B3ZLnsintro"
   },
   "source": [
    "Downsample by a factor of 2 in each dimension, which means we divided each brain into eight pieces. After that we have 696=87*8 pieces of sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "8A2anWjZVg4H",
    "outputId": "d3ccc730-8b47-4935-fd11-df74163143c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 176, 208, 176)\n",
      "(87, 176, 208, 176)\n"
     ]
    }
   ],
   "source": [
    "data_input2 = data_input.reshape(87,176,208,176)\n",
    "data_output2 = data_output.reshape(87,176,208,176)\n",
    "print(data_output2.shape)\n",
    "print(data_input2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29adpRD2BQ1I"
   },
   "outputs": [],
   "source": [
    "#remove outliers\n",
    "data_input2[data_input2 < 0] = 0\n",
    "data_input2[data_input2 > 255] = 255\n",
    "\n",
    "data_output2[data_output2 < 0] = 0\n",
    "data_output2[data_output2 > 255] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yU-mUFAfBQ5c"
   },
   "outputs": [],
   "source": [
    "#find the boundary of x, y, z axis in each image\n",
    "index = np.zeros((87,6))\n",
    "\n",
    "# x-axis\n",
    "for i in range(0,87):\n",
    "  for j in range(0,88):\n",
    "    if (np.sum(data_output2[i,j,:,:])) > 0:\n",
    "      if j > 0:\n",
    "        index[i,0] = j\n",
    "        break\n",
    "\n",
    "for i in range(0,87):\n",
    "  for k in range(175,88,-1):\n",
    "    if (np.sum(data_output2[i,k,:,:])) > 0:\n",
    "      if k < 175:\n",
    "        index[i,1] = k\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SZLSat6Bppz"
   },
   "outputs": [],
   "source": [
    "# y-axis\n",
    "for i in range(0,87):\n",
    "  for j in range(0,104):\n",
    "    if (np.sum(data_output2[i,:,j,:])) > 0:\n",
    "      if j > 0:\n",
    "        index[i,2] = j\n",
    "        break\n",
    "\n",
    "for i in range(0,87):\n",
    "  for k in range(175,88,-1):\n",
    "    if (np.sum(data_output2[i,:,k,:])) > 0:\n",
    "      if k < 175:\n",
    "        index[i,3] = k\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBSo5_BhBpsZ"
   },
   "outputs": [],
   "source": [
    "# z-axis\n",
    "for i in range(0,87):\n",
    "  for j in range(0,88):\n",
    "    if (np.sum(data_output2[i,:,:,j])) > 0:\n",
    "      if j > 0:\n",
    "        index[i,4] = j\n",
    "        break\n",
    "\n",
    "for i in range(0,87):\n",
    "  for k in range(175,88,-1):\n",
    "    if (np.sum(data_output2[i,:,:,k])) > 0:\n",
    "      if k < 175:\n",
    "        index[i,5] = k\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "Ykk6oLj_Bpur",
    "outputId": "75efcc7e-5ae5-4749-9a5d-0ae12c21302a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 176, 208, 176)\n",
      "(87, 176, 208, 176)\n",
      "(87, 80, 120, 120)\n",
      "(87, 80, 120, 120)\n"
     ]
    }
   ],
   "source": [
    "print(data_input2.shape)\n",
    "print(data_output2.shape)\n",
    "\n",
    "# The common boundaries are the following\n",
    "# x-axis (42,121)\n",
    "# y-axis (40,161)\n",
    "# z-axis (32,134)\n",
    "\n",
    "# Jimmy: We will adjust a few more or less pixels to fit a good\n",
    "#        dimension shape (Y-axis -8, Z-axis +17) for the model\n",
    "# Extract the part include ventricles\n",
    "data_input_cut = data_input2[:,42:122,41:161,24:144]\n",
    "data_output_cut = data_output2[:,42:122,41:161,24:144]\n",
    "print(data_input_cut.shape)\n",
    "print(data_output_cut.shape)\n",
    "#Final Dimension should be 80, 120,120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "-C5Gg7BxBpxq",
    "outputId": "8370aa44-ee5c-4de7-f04a-363afe3523e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fec1241fc88>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See the first image for example\n",
    "\n",
    "f, ax = plt.subplots(1,3)\n",
    "\n",
    "ax[0].imshow(data_input_cut[0,50,:,:],cmap=\"Greys\")\n",
    "ax[0].imshow(np.ma.masked_array(data_output_cut[0,50,:,:], data_output_cut[0,50,:,:]==0.0))\n",
    "\n",
    "ax[1].imshow(data_input_cut[0,:,50,:],cmap=\"Greys\")\n",
    "ax[1].imshow(np.ma.masked_array(data_output_cut[0,:,50,:], data_output_cut[0,:,50,:]==0.0))\n",
    "\n",
    "ax[2].imshow(data_input_cut[0,:,:,50],cmap=\"Greys\")\n",
    "ax[2].imshow(np.ma.masked_array(data_output_cut[0,:,:,50], data_output_cut[0,:,:,50]==0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPuckW2fGIxl"
   },
   "outputs": [],
   "source": [
    "data_input_cut_flipud = np.flip(data_input_cut, axis=1)\n",
    "data_output_cut_flipud = np.flip(data_output_cut, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M96bZz-NMkij"
   },
   "outputs": [],
   "source": [
    "data_input_cut_fliplr = np.flip(data_input_cut, axis=2)\n",
    "data_output_cut_fliplr = np.flip(data_output_cut, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "sB15KXbABQ-j",
    "outputId": "1b8f87d4-a443-4f73-ed6d-e422aaa20a85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fec11e65978>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See the first image for example\n",
    "\n",
    "f, ax = plt.subplots(1,3)\n",
    "\n",
    "ax[0].imshow(data_input_cut_flipud[0,52,:,:],cmap=\"Greys\")\n",
    "ax[1].imshow(data_input_cut_flipud[0,:,52,:],cmap='gist_gray_r')\n",
    "ax[2].imshow(data_input_cut_flipud[0,:,:,52],cmap='gist_gray_r')\n",
    "\n",
    "ax[0].imshow(1-data_output_cut_flipud[0,52,:,:],cmap=\"autumn\",alpha=.1)\n",
    "ax[1].imshow(1-data_output_cut_flipud[0,:,52,:],cmap=\"autumn\",alpha=.1)\n",
    "ax[2].imshow(1-data_output_cut_flipud[0,:,:,52],cmap=\"autumn\",alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbxtrl-xIvQE"
   },
   "outputs": [],
   "source": [
    "#Stick the flip data to previous data\n",
    "data_input_cut_all = np.concatenate((data_input_cut, data_input_cut_flipud, data_input_cut_fliplr), axis=0)\n",
    "data_output_cut_all = np.concatenate((data_output_cut, data_output_cut_flipud, data_output_cut_fliplr), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Y2dYvgChM0W3",
    "outputId": "bb540dcb-d6d3-4d55-c916-c34650661040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 80, 120, 120)\n",
      "(261, 80, 120, 120)\n"
     ]
    }
   ],
   "source": [
    "#check the total shape for both input and output\n",
    "print(data_input_cut_all.shape)\n",
    "print(data_output_cut_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "XTSdtIlnn_0g",
    "outputId": "78c74d86-758e-46b8-af76-ea1586d2dba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 80, 120, 120)\n",
      "(53, 80, 120, 120)\n",
      "(208, 80, 120, 120)\n",
      "(53, 80, 120, 120)\n"
     ]
    }
   ],
   "source": [
    "X_dataset = data_input_cut_all\n",
    "X_train = X_dataset[0:208,0:,0:,0:]\n",
    "X_test = X_dataset[208:,0:,0:,0:]\n",
    "\n",
    "Y_dataset = data_output_cut_all\n",
    "Y_train = Y_dataset[0:208,0:,0:,0:]\n",
    "Y_test = Y_dataset[208:,0:,0:,0:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "CURW5Z40oRV8",
    "outputId": "b2c91181-0161-4e57-b813-0b3f145acbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 80, 120, 120, 1)\n",
      "(53, 80, 120, 120, 1)\n",
      "(208, 80, 120, 120, 1)\n",
      "(53, 80, 120, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 80,120,120, 1)\n",
    "X_test = X_test.reshape(-1, 80,120,120,1)\n",
    "Y_train = Y_train.reshape(-1,80,120,120, 1)\n",
    "Y_test = Y_test.reshape(-1, 80,120,120, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XHal9QLAnfb9",
    "outputId": "436c703b-30f4-4d33-d9ce-536621c9a582"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D,Conv3D,Conv2DTranspose,MaxPooling3D,UpSampling3D\n",
    "from keras.layers import Input, Dense, Activation,Dropout\n",
    "from keras.layers import concatenate \n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kbDhPGyMnfYY",
    "outputId": "bce2895f-dba1-44f0-c5fd-42cc45f18d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 80, 120, 120, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 80, 120, 120, 224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 80, 120, 120, 1736        conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 40, 60, 60, 8 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 40, 60, 60, 1 3472        max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 40, 60, 60, 1 6928        conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 20, 30, 30, 1 0           conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 20, 30, 30, 3 13856       max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 20, 30, 30, 3 27680       conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20, 30, 30, 3 0           conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 10, 15, 15, 3 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 10, 15, 15, 6 55360       max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 10, 15, 15, 6 110656      conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10, 15, 15, 6 0           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 20, 30, 30, 6 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 20, 30, 30, 3 16416       up_sampling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20, 30, 30, 6 0           conv3d_6[0][0]                   \n",
      "                                                                 conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 20, 30, 30, 3 55328       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 40, 60, 60, 3 0           conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 40, 60, 60, 1 4112        up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 40, 60, 60, 3 0           conv3d_4[0][0]                   \n",
      "                                                                 conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 40, 60, 60, 1 13840       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 40, 60, 60, 1 6928        conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 80, 120, 120, 0           conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 80, 120, 120, 1032        up_sampling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 80, 120, 120, 0           conv3d_2[0][0]                   \n",
      "                                                                 conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 80, 120, 120, 3464        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 80, 120, 120, 1736        conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 80, 120, 120, 434         conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 80, 120, 120, 3           conv3d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 323,205\n",
      "Trainable params: 323,205\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "input_size = (80,120,120,1)\n",
    "\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "drop3 = Dropout(0.5)(conv3)\n",
    "pool3 = MaxPooling3D(pool_size=(2, 2, 2))(drop3)\n",
    "\n",
    "conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "\n",
    "up5 = Conv3D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(drop4))\n",
    "merge5 = concatenate([conv3,up5], axis = 4)\n",
    "conv5 = Conv3D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
    "\n",
    "up6 = Conv3D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv5))\n",
    "merge6 = concatenate([conv2,up6], axis = 4)\n",
    "conv6 = Conv3D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv3D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv3D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv6))\n",
    "merge7 = concatenate([conv1,up7], axis = 4)\n",
    "conv7 = Conv3D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv3D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "conv7 = Conv3D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "conv8 = Conv3D(1, 1, activation = 'sigmoid')(conv7)\n",
    "\n",
    "model = Model(input = inputs, output = conv8)\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmVV19FxnfW7"
   },
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "filepath = \"model_{epoch:03d}-{loss:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(X_train, \n",
    "                    Y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=1,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQ4d5Ub5iUHa"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"model_024-0.0565.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nh5AlEykdHgS",
    "outputId": "8325ae13-c7b0-436f-a328-f57de2538499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 208 samples, validate on 53 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1008s 5s/step - loss: 0.0570 - accuracy: 0.9717 - val_loss: 0.0502 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00001: saving model to model_001-0.0570.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 1013s 5s/step - loss: 0.0562 - accuracy: 0.9725 - val_loss: 0.0479 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00002: saving model to model_002-0.0562.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 1003s 5s/step - loss: 0.0570 - accuracy: 0.9733 - val_loss: 0.0518 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00003: saving model to model_003-0.0570.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 1003s 5s/step - loss: 0.0562 - accuracy: 0.9732 - val_loss: 0.0459 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00004: saving model to model_004-0.0562.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 1007s 5s/step - loss: 0.0547 - accuracy: 0.9732 - val_loss: 0.0466 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00005: saving model to model_005-0.0547.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 1003s 5s/step - loss: 0.0555 - accuracy: 0.9743 - val_loss: 0.0483 - val_accuracy: 0.9798\n",
      "\n",
      "Epoch 00006: saving model to model_006-0.0555.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 1011s 5s/step - loss: 0.0547 - accuracy: 0.9741 - val_loss: 0.0456 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00007: saving model to model_007-0.0547.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 1004s 5s/step - loss: 0.0530 - accuracy: 0.9743 - val_loss: 0.0483 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00008: saving model to model_008-0.0530.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 998s 5s/step - loss: 0.0529 - accuracy: 0.9747 - val_loss: 0.0468 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00009: saving model to model_009-0.0529.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 997s 5s/step - loss: 0.0505 - accuracy: 0.9759 - val_loss: 0.0577 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00010: saving model to model_010-0.0505.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 997s 5s/step - loss: 0.0556 - accuracy: 0.9766 - val_loss: 0.0447 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00011: saving model to model_011-0.0556.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 1009s 5s/step - loss: 0.0514 - accuracy: 0.9771 - val_loss: 0.0484 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00012: saving model to model_012-0.0514.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 1005s 5s/step - loss: 0.0505 - accuracy: 0.9766 - val_loss: 0.0498 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00013: saving model to model_013-0.0505.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 1001s 5s/step - loss: 0.0536 - accuracy: 0.9775 - val_loss: 0.0532 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00014: saving model to model_014-0.0536.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 1007s 5s/step - loss: 0.0597 - accuracy: 0.9746 - val_loss: 0.0528 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00015: saving model to model_015-0.0597.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 1005s 5s/step - loss: 0.0509 - accuracy: 0.9782 - val_loss: 0.0463 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00016: saving model to model_016-0.0509.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 1009s 5s/step - loss: 0.0490 - accuracy: 0.9793 - val_loss: 0.0443 - val_accuracy: 0.9842\n",
      "\n",
      "Epoch 00017: saving model to model_017-0.0490.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 1000s 5s/step - loss: 0.0474 - accuracy: 0.9797 - val_loss: 0.0439 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00018: saving model to model_018-0.0474.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 1001s 5s/step - loss: 0.0470 - accuracy: 0.9802 - val_loss: 0.0416 - val_accuracy: 0.9822\n",
      "\n",
      "Epoch 00019: saving model to model_019-0.0470.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 999s 5s/step - loss: 0.0470 - accuracy: 0.9802 - val_loss: 0.0417 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00020: saving model to model_020-0.0470.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 1002s 5s/step - loss: 0.0477 - accuracy: 0.9795 - val_loss: 0.0396 - val_accuracy: 0.9849\n",
      "\n",
      "Epoch 00021: saving model to model_021-0.0477.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 1001s 5s/step - loss: 0.0459 - accuracy: 0.9810 - val_loss: 0.0440 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00022: saving model to model_022-0.0459.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 1004s 5s/step - loss: 0.0461 - accuracy: 0.9800 - val_loss: 0.0412 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00023: saving model to model_023-0.0461.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 1012s 5s/step - loss: 0.0438 - accuracy: 0.9821 - val_loss: 0.0459 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00024: saving model to model_024-0.0438.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 1007s 5s/step - loss: 0.0428 - accuracy: 0.9826 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00025: saving model to model_025-0.0428.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 996s 5s/step - loss: 0.0427 - accuracy: 0.9823 - val_loss: 0.0405 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00026: saving model to model_026-0.0427.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 991s 5s/step - loss: 0.0428 - accuracy: 0.9829 - val_loss: 0.0445 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00027: saving model to model_027-0.0428.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 990s 5s/step - loss: 0.0424 - accuracy: 0.9832 - val_loss: 0.0389 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00028: saving model to model_028-0.0424.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 999s 5s/step - loss: 0.0420 - accuracy: 0.9834 - val_loss: 0.0375 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00029: saving model to model_029-0.0420.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 1004s 5s/step - loss: 0.0399 - accuracy: 0.9840 - val_loss: 0.0546 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00030: saving model to model_030-0.0399.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 1000s 5s/step - loss: 0.0403 - accuracy: 0.9838 - val_loss: 0.0458 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00031: saving model to model_031-0.0403.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 1008s 5s/step - loss: 0.0398 - accuracy: 0.9842 - val_loss: 0.0437 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00032: saving model to model_032-0.0398.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 1011s 5s/step - loss: 0.0387 - accuracy: 0.9847 - val_loss: 0.0360 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00033: saving model to model_033-0.0387.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 1004s 5s/step - loss: 0.0390 - accuracy: 0.9846 - val_loss: 0.0414 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00034: saving model to model_034-0.0390.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 996s 5s/step - loss: 0.0403 - accuracy: 0.9841 - val_loss: 0.0480 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00035: saving model to model_035-0.0403.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 996s 5s/step - loss: 0.0383 - accuracy: 0.9851 - val_loss: 0.0384 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00036: saving model to model_036-0.0383.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 1004s 5s/step - loss: 0.0388 - accuracy: 0.9850 - val_loss: 0.0469 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00037: saving model to model_037-0.0388.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 993s 5s/step - loss: 0.0382 - accuracy: 0.9852 - val_loss: 0.0375 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00038: saving model to model_038-0.0382.h5\n",
      "Epoch 39/40\n",
      " 57/208 [=======>......................] - ETA: 11:50 - loss: 0.0311 - accuracy: 0.9873"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-85aa8457cd26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     validation_data=(X_test, Y_test),callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Loading from checkpoint which we paused at 24th before\n",
    "epochs = 40\n",
    "new_model = load_model('/content/gdrive/My Drive/model_024-0.0565.h5')\n",
    "filepath = 'model_{epoch:03d}-{loss:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "history = new_model.fit(X_train,   Y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=1,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8gvU-oKWJYY"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"model_034-0.0390.h5\")\n",
    "files.download(\"model_035-0.0403.h5\")\n",
    "files.download(\"model_036-0.0383.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DmaWe-dJdtt_",
    "outputId": "f498fd76-c8c3-4ec7-d260-3f06827d73fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 208 samples, validate on 53 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1006s 5s/step - loss: 0.0396 - accuracy: 0.9848 - val_loss: 0.0461 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00001: saving model to model_001-0.0396.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 1001s 5s/step - loss: 0.0390 - accuracy: 0.9852 - val_loss: 0.0360 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00002: saving model to model_002-0.0390.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 940s 5s/step - loss: 0.0372 - accuracy: 0.9857 - val_loss: 0.0400 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00003: saving model to model_003-0.0372.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 934s 4s/step - loss: 0.0370 - accuracy: 0.9858 - val_loss: 0.0417 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00004: saving model to model_004-0.0370.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 945s 5s/step - loss: 0.0403 - accuracy: 0.9844 - val_loss: 0.0500 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00005: saving model to model_005-0.0403.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 944s 5s/step - loss: 0.0398 - accuracy: 0.9849 - val_loss: 0.0515 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00006: saving model to model_006-0.0398.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 949s 5s/step - loss: 0.0381 - accuracy: 0.9857 - val_loss: 0.0375 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00007: saving model to model_007-0.0381.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 949s 5s/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 0.0483 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00008: saving model to model_008-0.0363.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 939s 5s/step - loss: 0.0359 - accuracy: 0.9864 - val_loss: 0.0412 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00009: saving model to model_009-0.0359.h5\n",
      "Epoch 10/40\n",
      "208/208 [==============================] - 940s 5s/step - loss: 0.0352 - accuracy: 0.9867 - val_loss: 0.0439 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00010: saving model to model_010-0.0352.h5\n",
      "Epoch 11/40\n",
      "208/208 [==============================] - 938s 5s/step - loss: 0.0345 - accuracy: 0.9871 - val_loss: 0.0484 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00011: saving model to model_011-0.0345.h5\n",
      "Epoch 12/40\n",
      "208/208 [==============================] - 935s 4s/step - loss: 0.0352 - accuracy: 0.9866 - val_loss: 0.0487 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00012: saving model to model_012-0.0352.h5\n",
      "Epoch 13/40\n",
      "208/208 [==============================] - 937s 5s/step - loss: 0.0365 - accuracy: 0.9862 - val_loss: 0.0427 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00013: saving model to model_013-0.0365.h5\n",
      "Epoch 14/40\n",
      "208/208 [==============================] - 936s 4s/step - loss: 0.0350 - accuracy: 0.9868 - val_loss: 0.0625 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00014: saving model to model_014-0.0350.h5\n",
      "Epoch 15/40\n",
      "208/208 [==============================] - 945s 5s/step - loss: 0.0354 - accuracy: 0.9869 - val_loss: 0.0400 - val_accuracy: 0.9871\n",
      "\n",
      "Epoch 00015: saving model to model_015-0.0354.h5\n",
      "Epoch 16/40\n",
      "208/208 [==============================] - 951s 5s/step - loss: 0.0337 - accuracy: 0.9874 - val_loss: 0.0389 - val_accuracy: 0.9880\n",
      "\n",
      "Epoch 00016: saving model to model_016-0.0337.h5\n",
      "Epoch 17/40\n",
      "208/208 [==============================] - 952s 5s/step - loss: 0.0332 - accuracy: 0.9876 - val_loss: 0.0428 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 00017: saving model to model_017-0.0332.h5\n",
      "Epoch 18/40\n",
      "208/208 [==============================] - 950s 5s/step - loss: 0.0324 - accuracy: 0.9880 - val_loss: 0.0455 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00018: saving model to model_018-0.0324.h5\n",
      "Epoch 19/40\n",
      "208/208 [==============================] - 950s 5s/step - loss: 0.0328 - accuracy: 0.9879 - val_loss: 0.0384 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00019: saving model to model_019-0.0328.h5\n",
      "Epoch 20/40\n",
      "208/208 [==============================] - 940s 5s/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.0421 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00020: saving model to model_020-0.0327.h5\n",
      "Epoch 21/40\n",
      "208/208 [==============================] - 943s 5s/step - loss: 0.0317 - accuracy: 0.9883 - val_loss: 0.0358 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00021: saving model to model_021-0.0317.h5\n",
      "Epoch 22/40\n",
      "208/208 [==============================] - 947s 5s/step - loss: 0.0328 - accuracy: 0.9877 - val_loss: 0.0380 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00022: saving model to model_022-0.0328.h5\n",
      "Epoch 23/40\n",
      "208/208 [==============================] - 943s 5s/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.0496 - val_accuracy: 0.9834\n",
      "\n",
      "Epoch 00023: saving model to model_023-0.0315.h5\n",
      "Epoch 24/40\n",
      "208/208 [==============================] - 941s 5s/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 0.0373 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00024: saving model to model_024-0.0316.h5\n",
      "Epoch 25/40\n",
      "208/208 [==============================] - 943s 5s/step - loss: 0.0306 - accuracy: 0.9888 - val_loss: 0.0346 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00025: saving model to model_025-0.0306.h5\n",
      "Epoch 26/40\n",
      "208/208 [==============================] - 953s 5s/step - loss: 0.0319 - accuracy: 0.9885 - val_loss: 0.0359 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00026: saving model to model_026-0.0319.h5\n",
      "Epoch 27/40\n",
      "208/208 [==============================] - 960s 5s/step - loss: 0.0307 - accuracy: 0.9888 - val_loss: 0.0370 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00027: saving model to model_027-0.0307.h5\n",
      "Epoch 28/40\n",
      "208/208 [==============================] - 955s 5s/step - loss: 0.0311 - accuracy: 0.9886 - val_loss: 0.0364 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00028: saving model to model_028-0.0311.h5\n",
      "Epoch 29/40\n",
      "208/208 [==============================] - 965s 5s/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 0.0395 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00029: saving model to model_029-0.0310.h5\n",
      "Epoch 30/40\n",
      "208/208 [==============================] - 958s 5s/step - loss: 0.0308 - accuracy: 0.9890 - val_loss: 0.0395 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00030: saving model to model_030-0.0308.h5\n",
      "Epoch 31/40\n",
      "208/208 [==============================] - 957s 5s/step - loss: 0.0301 - accuracy: 0.9892 - val_loss: 0.0364 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00031: saving model to model_031-0.0301.h5\n",
      "Epoch 32/40\n",
      "208/208 [==============================] - 959s 5s/step - loss: 0.0291 - accuracy: 0.9894 - val_loss: 0.0427 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00032: saving model to model_032-0.0291.h5\n",
      "Epoch 33/40\n",
      "208/208 [==============================] - 960s 5s/step - loss: 0.0293 - accuracy: 0.9893 - val_loss: 0.0506 - val_accuracy: 0.9853\n",
      "\n",
      "Epoch 00033: saving model to model_033-0.0293.h5\n",
      "Epoch 34/40\n",
      "208/208 [==============================] - 958s 5s/step - loss: 0.0290 - accuracy: 0.9895 - val_loss: 0.0376 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00034: saving model to model_034-0.0290.h5\n",
      "Epoch 35/40\n",
      "208/208 [==============================] - 949s 5s/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.0521 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00035: saving model to model_035-0.0303.h5\n",
      "Epoch 36/40\n",
      "208/208 [==============================] - 956s 5s/step - loss: 0.0301 - accuracy: 0.9892 - val_loss: 0.0441 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00036: saving model to model_036-0.0301.h5\n",
      "Epoch 37/40\n",
      "208/208 [==============================] - 969s 5s/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.0422 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00037: saving model to model_037-0.0286.h5\n",
      "Epoch 38/40\n",
      "208/208 [==============================] - 964s 5s/step - loss: 0.0290 - accuracy: 0.9895 - val_loss: 0.0406 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00038: saving model to model_038-0.0290.h5\n",
      "Epoch 39/40\n",
      "208/208 [==============================] - 944s 5s/step - loss: 0.0291 - accuracy: 0.9895 - val_loss: 0.0389 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00039: saving model to model_039-0.0291.h5\n",
      "Epoch 40/40\n",
      "208/208 [==============================] - 964s 5s/step - loss: 0.0279 - accuracy: 0.9899 - val_loss: 0.0369 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00040: saving model to model_040-0.0279.h5\n"
     ]
    }
   ],
   "source": [
    "#Loading from checkpoint which we paused at 36th before\n",
    "epochs = 40\n",
    "new_model = load_model('/content/gdrive/My Drive/model_036-0.0383.h5')\n",
    "filepath = 'model_{epoch:03d}-{loss:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "history = new_model.fit(X_train,   Y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=1,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlABSY3J1xte"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"model_040-0.0279.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "colab_type": "code",
    "id": "3U_qUqYj5A1a",
    "outputId": "1a4837fe-f36f-442b-e986-731ace65143a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 208 samples, validate on 53 samples\n",
      "Epoch 1/40\n",
      "208/208 [==============================] - 1015s 5s/step - loss: 0.0275 - accuracy: 0.9899 - val_loss: 0.0377 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00001: saving model to model_001-0.0275.h5\n",
      "Epoch 2/40\n",
      "208/208 [==============================] - 1021s 5s/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 0.0345 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00002: saving model to model_002-0.0283.h5\n",
      "Epoch 3/40\n",
      "208/208 [==============================] - 1023s 5s/step - loss: 0.0277 - accuracy: 0.9900 - val_loss: 0.0576 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00003: saving model to model_003-0.0277.h5\n",
      "Epoch 4/40\n",
      "208/208 [==============================] - 1021s 5s/step - loss: 0.0282 - accuracy: 0.9897 - val_loss: 0.0314 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00004: saving model to model_004-0.0282.h5\n",
      "Epoch 5/40\n",
      "208/208 [==============================] - 1015s 5s/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.0421 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00005: saving model to model_005-0.0274.h5\n",
      "Epoch 6/40\n",
      "208/208 [==============================] - 1016s 5s/step - loss: 0.0270 - accuracy: 0.9901 - val_loss: 0.0316 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00006: saving model to model_006-0.0270.h5\n",
      "Epoch 7/40\n",
      "208/208 [==============================] - 1021s 5s/step - loss: 0.0271 - accuracy: 0.9901 - val_loss: 0.0416 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00007: saving model to model_007-0.0271.h5\n",
      "Epoch 8/40\n",
      "208/208 [==============================] - 1028s 5s/step - loss: 0.0277 - accuracy: 0.9900 - val_loss: 0.0369 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00008: saving model to model_008-0.0277.h5\n",
      "Epoch 9/40\n",
      "208/208 [==============================] - 1030s 5s/step - loss: 0.0296 - accuracy: 0.9892 - val_loss: 0.0389 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00009: saving model to model_009-0.0296.h5\n",
      "Epoch 10/40\n",
      " 17/208 [=>............................] - ETA: 15:28 - loss: 0.0283 - accuracy: 0.9892"
     ]
    }
   ],
   "source": [
    "#Loading from checkpoint which we paused at 40th before\n",
    "epochs = 40\n",
    "new_model = load_model('/content/gdrive/My Drive/model_040-0.0279.h5')\n",
    "filepath = 'model_{epoch:03d}-{loss:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "history = new_model.fit(X_train,   Y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=1,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_e8pDuLTnfTM"
   },
   "outputs": [],
   "source": [
    "# Change the directory accordingly here\n",
    "X_testing= np.load('OAS1_0084_MR.npz')['arr_0'][44:132,52:156,44:132]\n",
    "Y_testing= np.load('OAS1_0084_MRseg.npz')['arr_0'][44:132,52:156,44:132]\n",
    "\n",
    "X_testing = X_testing.reshape(1,88,104,88,-1)\n",
    "\n",
    "print(X_testing.shape)\n",
    "print(Y_testing.shape)\n",
    "\n",
    "y_predict = np.around(model.predict(X_testing))\n",
    "y_predict = y_predict.reshape(-1,88,104,88)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOc9O3eGnfRm"
   },
   "outputs": [],
   "source": [
    "PJ = y_predict.reshape(-1)\n",
    "AJ = Y_testing.reshape(-1)\n",
    "\n",
    "count = 0\n",
    "for i in range(PJ.shape[0]):\n",
    "    if PJ[i] == AJ[i]:\n",
    "        if PJ[i]==1:\n",
    "            count += 1\n",
    "        \n",
    "total = np.count_nonzero(big_Y_plot)\n",
    "        \n",
    "print(count)      \n",
    "print(\"Predicted Accuracy :\", count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14J86b8bnfOl"
   },
   "outputs": [],
   "source": [
    "#PREDICTION\n",
    "\n",
    "f, ax = plt.subplots(1,3)\n",
    "\n",
    "X_plot = X_testing.reshape(88,104,88)\n",
    "y_plot = y_predict.reshape(88,104,88)\n",
    "\n",
    "# Since we truncated 25% of data on each side, we need to recalculate the index accordingly\n",
    "\n",
    "ax[0].imshow(X_plot[56,:,:],cmap=\"Greys\")\n",
    "ax[0].imshow(np.ma.masked_array(y_plot[56,:,:], y_plot[56,:,:]==0.0))\n",
    "\n",
    "ax[1].imshow(X_plot[:,18,:],cmap=\"Greys\")\n",
    "ax[1].imshow(np.ma.masked_array(y_plot[:,18,:], y_plot[:,18,:]==0.0))\n",
    "\n",
    "ax[2].imshow(X_plot[:,:,6],cmap=\"Greys\")\n",
    "ax[2].imshow(np.ma.masked_array(y_plot[:,:,6], y_plot[:,:,6]==0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q2uQudg9nfLa"
   },
   "outputs": [],
   "source": [
    "big_Y_plot = Y_testing.reshape(88,104,88)\n",
    "\n",
    "f, ax = plt.subplots(1,3)\n",
    "\n",
    "ax[0].imshow(X_plot[56,:,:],cmap=\"Greys\")\n",
    "ax[0].imshow(np.ma.masked_array(big_Y_plot[56,:,:], big_Y_plot[56,:,:]==0.0))\n",
    "\n",
    "ax[1].imshow(X_plot[:,18,:],cmap=\"Greys\")\n",
    "ax[1].imshow(np.ma.masked_array(big_Y_plot[:,18,:], big_Y_plot[:,18,:]==0.0))\n",
    "\n",
    "ax[2].imshow(X_plot[:,:,6],cmap=\"Greys\")\n",
    "ax[2].imshow(np.ma.masked_array(big_Y_plot[:,:,6], big_Y_plot[:,:,6]==0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnJg7oPWnfG1"
   },
   "outputs": [],
   "source": [
    "print(\"Correct Segmented Percentage: \",round(np.count_nonzero(big_Y_plot)/PJ.shape[0],5))\n",
    "print(\"Correct Empty Part Percentage: \", round(np.count_nonzero(big_Y_plot==0)/PJ.shape[0],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hB3ppCU-nfDa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygJK4aEInfBO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Data Aug",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
